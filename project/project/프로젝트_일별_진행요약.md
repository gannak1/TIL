### 1일차(02.15)

1. 멤버 소개
2. 팀명 정하기 -> NT
3. 일정계획

- 2/15~2/19 : 전처리, EDA
- 2/20 : 기획안 작성, 어떤 모델 쓸 지, 모델링 팀 구성
- 2/21 : 전처리, EDA 1차 완료
- 2/22 ~ 2/28 :  모델링, 성능평가
- 3/1~3/2 : PPT 제작(이서현) 및 주피터 정리(남궁정후), 발표 준비(김홍비, 정영훈, 이재호)
- 3/3 : 발표

4. 각자 데이터 보면서 생각해보기



### 2일차(02.16)

#### 1. 전처리

- `sales_train` 데이터

1. 중복값 -> 삭제 
2. 이상치
   1. 판매갯수 (-) -> 환불처리로 파악, (구매 행과 같이) 삭제
   1. 판매가격 (-) -> 삭제
   2. 판매갯수 큰 값 ESD, 400, 500-> 500
   2. 가격 큰 값(이상치) 처리 ESD, 40000, 50000 -> 50000
3. 결측치 -> 없음.

4. date -> object -> datetime으로 변경



- 러시아어
- 1. 라벨인코딩만!!
  2. 지역 별 분석



[추후 해야할 전처리]

1. 데이터 merge

2. 스케일링, 표준화

   1. 스케일링

   - standardscaler -> 표준 정규분포 사용
   
   
      - minmax -> 최소, 최대값 사용
   
   
      - MaxAbsscale -> 최대 절댓값 사용
   
   
      - robust_scale -> 중위수, 사분위범위 사용
   
        
   

   2. 인코딩

   - 레이블 인코딩

   - 원-핫 인코딩

   - 더미변수(get_dummies)

   - 평균값 인코딩



#### 2. EDA

- boxplot 꼭 사용! (강사님 얘기론)



[Jupyter notebook]

정리하면서 진행



[오늘 할 일]

- 러시아어 라벨인코딩,  지열 컬럼 만들기
  - item_name
  - item_category_name
  - shop_name
- date, date_block, 가격, 상점id, 상품id, 지역, 월 별 구매 수량 등으로 EDA 분석해보기 -> 추가 컬럼 생각하기





### 3일차(02.17)

#### 1. 전처리

1. 전처리 (러시아어 라벨 인코딩)

- items data 

- item_categorys data

- shops data

- test data



#### 2. EDA

1. 이상치 (월별 item 가격, 거래량 boxplot)
2. 월별 거래수

3. 월별 거래된 shop 수, 월별 거래된 item 수
4. 가격별 item 하루 판매 개수
5. 월별 총 판매금액
6. 월별 총 판매개수
7. 품목별 판매량
8. 카테고리별 판매 금액
9. 연도별 판매량
10. 월별 판매량
11. 연도별 판매 총액
12. 월별 상점별 판매개수
13. 월별 카테고리별 판매개수
14. 도시별 판매개수



#### 3. train data



- data_block_num
- shop_id
- item_id
- item_category_id
- city_id
- type_id



- item_cnt_month (item별 월 거래수) *
- shop_cnt_month( shop 별 월 거래수) *
- shop별 item별 가격 -
- item 별 판매 주기 *
- 12, 1월 -> 1, 나머지 -> 0 인코딩 *



월별 item 평균 판매량 *



[오늘 할 일]

- train 데이터에 변수 어떤걸 넣을지 각자 생각해서 코드 짜오기(2개씩)

  



### 4일차(02.18)

[회의 계획]

- 같이 코드 정리 하기(dataframe 짜기) ***

- 전처리 전 EDA, 전처리 후 EDA로 나누기

- 정후님이 매 회의 전까지 코드를 다듬어 주시면 좋을 것 같습니다
  - (제목, 주석, 그래프 (스타일 통합, 제목 달기), 팀원 데이터 (뒤죽박죽 복붙 된 데이터) 읽기 쉽게 정리 등)



- 일요일 회의 전까지 기획안은 어떤식으로 쓸 지 생각해보기(역할, 전처리, 스케일링, 모델링, 모델 성능평가)
- 월요일 회의 전까지 각자 코드 보면서 
  - 수정할 부분 보고, 추가 or 삭제할 변수, 그래프(EDA) 생각
  - 러시아어, 이상치 등 전처리 더 할 거(데이터 더 분석해보기)

- 월요일 회의 때 전처리 1차 확정(같이 코드 정리하기)



- 박혜정 강사님 팁: 전처리 후 변수 추가하기



2014~2015 러시아 경제 위기

2014년 기간 [러시아 루블](https://ko.wikipedia.org/wiki/러시아_루블)에 대한 [통화](https://ko.wikipedia.org/wiki/통화)의 평가절하가 일어나고 [러시아 경제](https://ko.wikipedia.org/wiki/러시아_경제)의 둔화된 현상이다.[[3\]](https://ko.wikipedia.org/wiki/2014~2015년_러시아_경제_위기#cite_note-financialcrisis-3)[[4\]](https://ko.wikipedia.org/wiki/2014~2015년_러시아_경제_위기#cite_note-sanctions-4) 이 경제 위기는 러시아의 최대 수출 품목인 [석유](https://ko.wikipedia.org/wiki/석유) 가격이 2014년 6월에서 12월동안 50% 이상 감소하면서 쇠퇴에 영향을 주었다.[[3\]](https://ko.wikipedia.org/wiki/2014~2015년_러시아_경제_위기#cite_note-financialcrisis-3)[[5\]](https://ko.wikipedia.org/wiki/2014~2015년_러시아_경제_위기#cite_note-oilpricedecline-5)

이 경제 위기는 러시아의 소비자와 기업 모두에게 큰 영향을 주었으며, 금융계에도 부정적인 영향을 주었다. 특히 러시아 주식 시장인 [RTS 인덱스](https://ko.wikipedia.org/w/index.php?title=RTS_인덱스&action=edit&redlink=1)는 12월 초부터 12월 16일까지 30$나 감소하였다.[[6\]](https://ko.wikipedia.org/wiki/2014~2015년_러시아_경제_위기#cite_note-russianstocks-6)

2014년 2월 28일쯤에 우크라이나 침공

 2015년 2월 21일에 신용등급 떨어짐



### 5일차(02.19)

- 기확안 어떻게 작성할 건지 생각하기
- 전처리 부분 수정 할 부분 생각하기



### 6일차(02.20)

#### 1. 전처리

1. city 컬럼에 있는 ! 문자 기호 제거
2. city 
   - Интернет-магазин :온라인 상점?
   - Выездная : 지명인지 모르겠음, 어디에도 지명이라고 안나옴

3. features 생성

- train 데이터에 test 데이터에 맞는 ID 컬럼 만들기 - 김홍비

- category_cnt_month : date_block_num, category 별 판매된 제품의 수 - <u>김홍비</u>

- city_cnt_month : date_block_num, city 별 판매된 제품의 수 - <u>남궁정후</u>

- type_cnt_month : date_block_num, type 별 판매된 제품의 수 - <u>이서현</u>

- item_shop_cnt_month : date_block_num, <u>shop, item</u> 별 판매된 제품의 수 - <u>정영훈</u>
- shop, item별 가격 - <u>남궁정후</u>

- 2014년 2월 28일 이전 이후 - <u>정영훈</u>

- 상품 판매 추세 코드를 만들어보고 싶다. -> 각자 생각해보기
  - shop별 item이 판매되는 주기, 추세 


- PCA  활용



#### 2. 기획안 작성

1. 모델링 역할 나누기

> GROUP 1

- 1. <u>회귀분석</u> : LinearRegression - 남궁정후 ***

- 2. <u>랜덤포레스트</u> : RandomForestRegressor - 정영훈 ***

- 3. <u>KNN 회귀</u> : KNeightborsRegressor - 이서현 ***

- 4. <u>서포트 벡터머신</u> : LinearSVR-> 선형, 비선형 모두 가능 - 김홍비 ***



> GROUP2

- 5. XGBoost - XGBRegressor : 정영훈 ***
- 6. LightGBM -  LGBRegressor : 이서현 ***
- 7. GradientBoosting - GradientBootingRegressor : 남궁정후 ***
- 8. Stacking - StackingRegressor : 김홍비



> GROUP3

- 9. SGDRegressor - 정영훈

- 10. MLPRegressor - 남궁정후

- 11. 가우시안 프로세스 회귀 - 김홍비

  



### 7일차(02.21)

#### 1. 전처리

[해야할 것 (14:00 ~ 17:00)] (* : 했음)

- shop_id, item_id에 따라 월 별로 묶은 df에 어떻게 train, test merge 할 지 *

  - 결측값 처리

  - 데이터 타입(진수) 변경 *

- feature 변수 추가* -> EDA(시각화)를 바탕으로

  - category_cnt_month : date_block_num, category 별 판매된 제품의 수 
  - city_cnt_month : date_block_num, city 별 판매된 제품의 수
  - type_cnt_month : date_block_num, type 별 판매된 제품의 수
  - item_shop_cnt_month : date_block_num, <u>shop, item</u> 별 판매된 제품의 수 
  - shop, item별 가격
  - 연말
  - 2014년 2월 28일 이전 이후

  ![image-20220221171745278](프로젝트_일별_진행요약.assets/image-20220221171745278.png)



- 라벨인코딩 -> 원-핫 인코딩 / 평균 인코딩 *

- 스케일링

  



- PCA

- 기획안 수정 및 제출
  - 데이터 Type, Shape, 상관관계, 기초통계량, 
  - DBSCAN -> 비지도학습, 안될 것 같음



#### 2. 오늘의 과제



- 재고관리 -> 성능에 따라?
- <u>시계열(일자별, 요일별)</u>  -> 
- 지도 -> 성능에 따라?
- <u>shop별(영업하는 달, 안하는 달)</u> - 남궁정후
- 폐업한 가게



- 일자별, 요일별로 더 디테일하게
- merge도 어떻게 할 지... 월별이 답이 아니다
- 월별로 합칠 때 NaN값을 어떻게 처리할 지
- rolling ?
- test 데이터 건들지 말기?
- y값(연속형)도 스케일 할 필요가 있다?
- 정규화를 너무 디테일하게 하면 현실적인게 떨어짐...



### 8일차(02.22)

#### 1. 전처리

shop_id

- 판매가 되었던 시점과 판매가 안 된 시점 파악 -> 영업과 상관없이

- 영업했던날과 하지 않았던 날(일자별)
- 전체적인 제품 판매개수와 수익을 만들어서 주말과 평일별로 차이가 있나 살펴보려함.

요일별

- 토요일에 1.5배정도 거래량이 많다

계절별

- 비슷비슷함. 

판매량 변동율

- 뒤죽박죽

지도

- 도시별 얼마나 팔렸는지 circle 크기별로 지도에 시각화

폐업한 가게

- 가장 최근에 판매된 기준부터 6개월 동안 거래가 없으면 예측 -> 0



[우승자 코드 참고]

lag i =  1, 2, 3, 6, 12

1. 여러가지 조합 -> lag -> 남궁정후

   - i달 전의 동일 shop, 동일 제품의 판매량

   - 월 평균 판매 수량

   - 월별 item별 평균 판매 수량

   - 월별, shop_id별 평균 판매 수량

   - 월별 category별 평균 판매 수량

   - 월별 shop별, category별 평균 판매 수량

   - 월별 shop별, type_code별 평균 판매 수량

   - 월별 city_code별 평균 판매 수량

   - 월별 item별, city_code별 평균 판매 수량

   - 월별 type_code별 평균 판매 수량

2. 가격 변동 -> 이서현

   - item_id별 평균 가격
   - 월별 item_id별 평균 가격
   -  해당 월별 item_id별 평균 가격이 어떤 가격 트렌드를 가지고 있는지

3. shop revenue trend

4. 요일, 공휴일, 계절 등등 -> 김홍비

5. 도시, 상점 -> 정영훈

6. trend

   - 마지막 판매가 있고 나서부터 지난 개월 수 (shop-item pair별, item별)

   - 첫번째 판매 후 지난 개월 수 (shop-item pair, item pair 별)

7. lag를 12까지 사용했으므로 첫 12달은 drop한다



#### 2. 오늘의 과제

1. 시계열 분석
2. 우승자 코드 lag 공부하고 코드짜오기(시계열)
2. 추가 features 있으면 생각해보기

4. 추가로 생각할 거(목요일까지) ->  목요일까지 전처리 무조건 끝내기!!!

- 만든 변수 합치기

- 데이터 프레임 만들기 - 데이터 어떻게 합칠지

- 테스트데이터 어떻게 처리할 건지
  - date_block_num 변수 만든 후 값을 34로 채움

- item_price_by_id 
  - item 평균값으로 대체
  - 그래도 남은 NaN값 대체 어떻게 할 지
- 2014년 2월 28일 전후(러시아 경제 위기) -> 생각해보기
- 라벨인코딩 -> 원-핫 인코딩 / 평균 인코딩
  - 12월 1월로 나눌지, 12월로 나눌지
  - 인코딩은 어떤걸로 사용할 지
- 스케일링
- (PCA로 feature 변수 생성해보기)



#### 3. 기획안 피드백

1. 최종발표 : 실제발표시간 (20분(발표), 10분(질의응답), 20분(코드리뷰), 오후 시간
	-  ppt , 코드리뷰 나눠서 발표
	-  2번째 프로젝트부터 자료는 Github에 올리기 -> 동기들만 볼 수 있도록
	-  3월 1일에 밖에서 만나기...? -> AI EXPO



###  9일차(02.23)

#### 1. 전처리

[회의 계획] (14:00 ~ 17:20) -> 전처리 끝내보기,,,

1. features 변수

   - 시계열 및 변수 만든거 발표

   - 최종 변수 정하기(정리하면서)
     - lag로 나눌 변수 정하기 (lag 사용할 시)
     - 인코딩 필요한 변수 -> 인코딩하기 (라벨인코딩 : 12월, 페업여부, 계절별(봄, 여름, 가을, 겨울 변수))
       - 원핫 인코딩, 평균값 인코딩

   - 변수명 다같이 알아볼 수 있게 정리하기

2. test data 처리

3. data merge
   - 결측치 처리

4. 스케일링

5. 모델링

- 원핫인코딩, 평균값 인코딩, 폐업여부 라벨인코딩



#### 코드북

| item_cnt_month                 | item 총 판매량                                 |
| ------------------------------ | ---------------------------------------------- |
| shop_cnt_month                 | shop 별 item 총 판매량                         |
| #dec                           | #12,1월 -> 1, 그 외 -> 0 라벨인코딩            |
| category_cnt_month             | category별  item 총 판매량                     |
| city_cnt_month                 | city별  item 총 판매량                         |
| type_cnt_month                 | type별  item 총 판매량                         |
| item_shop_price                | item별, shop별 item 가격                       |
| item_shop_cnt_month            | item별, shop별, item 총 판매량 (lag 1,3,6,12)  |
| season_avg_item_cnt            | 계절별  item 평균 판매량                       |
| season_item_shop_avg_cnt       | 계절별 item별 shop별 item 평균 판매량          |
| season_shop_avg_cnt            | 계절별 shop별 item 평균 판매량                 |
| season_city_avg_cnt            | 계절별 city별  item 평균 판매량                |
| season_type_avg_cnt(만들기)    | 계절별 type별  item 평균 판매량                |
| #dec_item_avg_cnt(12월로 수정) | #12(연말) 별 item  평균 판매량                 |
| #shop_close                    | #폐업 라벨인코딩                               |
| date_avg_item_cnt              | 월별  item  평균 판매량   (lag 1, 3,6,12)      |
| date_item_avg_item_cnt         | 월별 item별 item  평균 판매량                  |
| date_shop_avg_item_cnt         | 월별 shop별 item  평균 판매량   (lag 1,3,6,12) |
| date_cat_avg_item_cnt          | 월별 category별 item  평균 판매량              |
| date_shop_cat_avg_item_cnt     | 월별 shop별 category별 item  평균 판매량       |
| date_city_avg_item_cnt         | 월별 city별 item  평균 판매량                  |
| date_item_city_avg_item_cnt    | 월별 item별 city별 item  평균 판매량           |



#### 2. 오늘의 과제

- 전처리 

1. 김홍비, 남궁정후 - 코드 짠거 정리파일에 올리기
2. (1)원핫인코딩, (2)평균값 인코딩 - dec, 계절, 폐업여부 -> 김홍비

(미리 코드 짜놓기)

1. Nan값 평균값으로 대체, 그래도 남은 부분은 0으로 대체 -> 남궁정후
2. 스케일링(standardscaler) -> 정영훈

- shape 안 맞는 거 오류 찾기



 -> 전처리 완료

- 모델링

group 1 공부해오기



------

맡은 모델 공부해오기

- 도움 되는 사이트나 코드 있으면 서로 공유

ppt, notebook 정리, 발표 준비 틈틈히 미리 해놓고 같이 수정하기

- EDA 시각화 자료 어떤거 넣을 건지도 생각하기





### 10일차(02.24)

#### 1. 전처리

1. features 변수 Null 값 처리
   - item_shop_price : Nan값 중앙값으로 대체
   - lag 변수들 Nan값 : 0으로 처리

2. 스케일링
   - StandardScale

3. 파일 저장
   - pickle
4. 변수 선택

5. 모델링 

- r2_score이 1이 나옴 -> 뭔가 잘못됨.





#### 2. 오늘의 과제

1. 필요한 features 변수 골라내기 (**2/25 회의 전까지 코드 올리기!**)

- EDA 분석

​		EDA분석 통해서 pairplot 그려 상관성 보기
​		상관관계성이 높은 변수를 일단 list 로 넣으세요
​		for 문 >>> 상관관계 높은 리스트 원소 인덱스 접근해서 상관관계 개별적으로 확인
​		mask 2 를 생성

- PCA 해보기 2개로
  mlpregressor 가져와서 모델 성능보기
  mask 성능 개선 여부 확인 mlpregressor

​		pca.explained_variance_
​		주성분의 분산 설명력
​		pca.components_
​		위 두개 사용

- 상관분석



-> 변수 정한 코드 꼭! 드라이브에 올려주기

-> 코드 미리 보고온 뒤 회의 때 결정



2. 맡은 모델 두 개씩 돌려보기 **(일요일 아침(9:00)까지 해오기!!)**

> GROUP 1

- 1. <u>회귀분석</u> : LinearRegression - 남궁정후 ***

- 2. <u>랜덤포레스트</u> : RandomForestRegressor - 정영훈 ***

- 3. <u>KNN 회귀</u> : KNeightborsRegressor - 김홍비 ***

- 4. <u>서포트 벡터머신</u> : LinearSVR-> 선형, 비선형 모두 가능 - 김홍비 ***



> GROUP2

- 5. XGBoost - XGBRegressor : 정영훈 ***
- 6. LightGBM -  LGBRegressor : 김홍비 ***
- 7. GradientBoosting - GradientBootingRegressor : 남궁정후 ***



3. 역할 정하기
   1. PPT : 내일부터
      - 서론, 전처리, EDA, 모델링, 결론
   2. notebook
   3. 발표
      - PPT 발표 - 질의응답 - 코드리뷰 -> 팀 당 1시간?



### 11일차(02.25)

#### 1. 전처리

1. 행 제거한 부분
   - 가격 음수
   - 환불처리
   - 첫 12달

2. NaN값 처리
   - item_cnt_month 
     - 해당 월에 해당 아이템이 판매된 이력이 없다고 봐서 0으로 처리했었음
     - clip(0,30)
   - shop_item_price 변수 삭제 -> item_price로 변경
     - Nan값은 0으로
   - lags Nan값 -> 0
   
3. 추가한 변수
   - sub_id 
     - 눈에 띄게 잘보이는 판매품복은 게임관련 제품이라(type 말고 sub만 보기로 함)
   - month
   - date_item_city_a9vg_item_cnt_lag1
   
4. 제거한 변수
   - type_id
   - dec
   - close
   - season 원-핫인코딩, 평균인코딩 제거 -> id처럼 간주하기

5. 수정
   - type 별로 만든 변수 -> sub 별로 변경



#### 2. 모델링

1. 오늘 수정한 data2 -> MLPReg 



#### 3. 발표 준비

1. ppt 만들기
2. jupyter notebook 코드 정리



#### 4. 오늘의 과제(강사님 피드백)

1. 변수 상관관계 하나하나 파악하기
2. pairplot 꼭 그려보기
3. rolling, shift 꼭 사용하기
4. **lags 변수에 NaN값을 0으로 처리하면 문제** -> ffillna도 생각하기
5. 일요일까지 하기로 한 부분
   - EDA 분석

​		EDA분석 통해서 pairplot 그려 상관성 보기
​		상관관계성이 높은 변수를 일단 list 로 넣으세요
​		for 문 >>> 상관관계 높은 리스트 원소 인덱스 접근해서 상관관계 개별적으로 확인
​		mask 2 를 생성

- PCA 해보기 2개로
  mlpregressor 가져와서 모델 성능보기
  mask 성능 개선 여부 확인 mlpregressor

​		pca.explained_variance_
​		주성분의 분산 설명력
​		pca.components_
​		위 두개 사용

- 상관분석