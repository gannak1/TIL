{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the core part of my framework I use to test different ideas and features. I didn't include all the code as it would make the competition less exciting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath  = './data/'\n",
    "adpath ='./input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data loading\n",
    "\n",
    "df_train = pd.read_csv(dpath + 'sales_train.csv')\n",
    "df_test = pd.read_csv(dpath + 'test.csv', index_col='ID')\n",
    "\n",
    "df_shops = pd.read_csv(dpath + 'shops.csv', index_col='shop_id')\n",
    "\n",
    "df_items = pd.read_csv(dpath + 'items.csv', index_col='item_id')\n",
    "df_itemcat = pd.read_csv(dpath + 'item_categories.csv', index_col='item_category_id')\n",
    "\n",
    "sample_submission = pd.read_csv(dpath + 'sample_submission.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calendar\n",
    "\n",
    "calendar = pd.read_csv(adpath + 'calendar.csv', dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shops\n",
    "\n",
    "def shop_name2city(sn):\n",
    "    sn = sn.split()[0]\n",
    "    if sn == 'Цифровой' or sn == 'Интернет-магазин': sn = 'Internet'\n",
    "    if sn[0] == '!': sn = sn[1:]  \n",
    "    return sn\n",
    "\n",
    "df_shops['city'] = df_shops['shop_name'].apply(shop_name2city)\n",
    "df_shops['city_enc'] = LabelEncoder().fit_transform(df_shops['city']).astype('int8')\n",
    "\n",
    "city_info = pd.read_pickle(adpath + 'city_info.pkl')\n",
    "\n",
    "df_shops['city_size'] = df_shops['city'].map(city_info['city_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define items class\n",
    "\n",
    "class Items():\n",
    "\n",
    "    def __init__(self, df_items, df_itemcat):\n",
    "        \n",
    "        self.df_items    = df_items\n",
    "        self.df_itemcat  = df_itemcat\n",
    "        \n",
    "        self.set_hl_cat()\n",
    "        self.make_items_ext()\n",
    "        \n",
    "        self.item_features = ['item_category_id', 'hl_cat_id']\n",
    "\n",
    "    def set_hl_cat(self):\n",
    "        \n",
    "        self.df_itemcat['hl_cat_id'] = self.df_itemcat['item_category_name'].str.split(n=1, expand=True)[0]\n",
    "        self.df_itemcat['hl_cat_id'] = LabelEncoder().fit_transform(self.df_itemcat['hl_cat_id'])\n",
    "        \n",
    "    def make_items_ext(self):\n",
    "    \n",
    "        self.df_items = df_items.merge(self.df_itemcat, how = 'left', \n",
    "                                       left_on = 'item_category_id', right_index = True)\n",
    "\n",
    "    def get_items_df(self):\n",
    "        \n",
    "        return self.df_items[self.item_features].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = Items(df_items, df_itemcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train-test class\n",
    "\n",
    "class TT_Extended():\n",
    "    \n",
    "    def __init__(self, df_train, df_test, items, df_shops, calendar, cmode, verbose=True):\n",
    "        \n",
    "        self.info = verbose\n",
    "        \n",
    "        self.df_train  = df_train.copy()\n",
    "        self.df_test   = df_test.copy()\n",
    "        self.df_shops  = df_shops.copy()\n",
    "        self.calendar  = self.set_calender(calendar.copy())\n",
    "        \n",
    "        self.idx_columns = ['date_block_num', 'shop_id', 'item_id']\n",
    "        \n",
    "        self.df_test['date_block_num'] = 34\n",
    "        self.df_test['item_cnt_month'] = 0.\n",
    "        self.df_test['item_cnt_month'] = self.df_test['item_cnt_month'].astype('float32')\n",
    "        \n",
    "        self.df_train[self.idx_columns] = self.df_train[self.idx_columns].astype('int32')\n",
    "        self.df_test[self.idx_columns]  = self.df_test[self.idx_columns].astype('int32')\n",
    "        \n",
    "        self.df_train_cleaning(cmode)\n",
    "        \n",
    "        self.item_mean_features = []\n",
    "        self.shop_mean_features = []\n",
    "        self.lag_names_to_clip  = []\n",
    "        \n",
    "        self.df_items = items.get_items_df()\n",
    "        self.item_ext_features = list(self.df_items.columns)\n",
    "        self.df_items_ext = self.items_ext()\n",
    "        \n",
    "        self.df_bb = self.build_bb()\n",
    "        \n",
    "        # Critical point: 0 or None\n",
    "        self.df_train_ext = self.df_train_agg(cmin = 0, cmax = 1000, drop = None)\n",
    "        \n",
    "        self.add_test_df()\n",
    "        \n",
    "        self.df_train_ext = self.df_train_extention()\n",
    "        \n",
    "    def df_train_cleaning(self, mode):\n",
    "        \n",
    "        assert mode in ['keep', 'drop', 'block', 'total', 't+b']\n",
    "        \n",
    "        # 'keep'  - do nothing\n",
    "        # 'drop'  - drop all negative rows\n",
    "        # 'block' - remove item_id if its sum is negative in a block\n",
    "        # 'total' - remove item_id if its total sum is negative\n",
    "        # 't+b'   - 'total' + 'block'\n",
    "        \n",
    "        if self.info: print('Cleaning train dataframe... ( Mode -', mode, ')')\n",
    "         \n",
    "        # Remove very noisy shops \n",
    "        \n",
    "        shop_idx = self.df_train[(self.df_train['shop_id'] == 9)  | \n",
    "                                 (self.df_train['shop_id'] == 20)].index\n",
    "        self.df_train.drop(shop_idx, inplace=True)\n",
    "        \n",
    "        \n",
    "        self.df_train = self.df_train[(self.df_train['item_price'] > 0) & \n",
    "                                      (self.df_train['item_price'] < 51000)]\n",
    "        self.df_train = self.df_train[self.df_train['item_cnt_day'] <= 1000]\n",
    "\n",
    "        shop_repl_dict = {0 : 57, 1 : 58, 11 : 10, 40 : 39}\n",
    "    \n",
    "        self.df_train['shop_id'] = self.df_train['shop_id'].apply(\n",
    "                                   lambda s: shop_repl_dict.get(s) if s in shop_repl_dict else s)    \n",
    "            \n",
    "            \n",
    "        if   mode == 'drop':\n",
    "            self.df_train = self.df_train[self.df_train['item_cnt_day'] > 0]\n",
    "            \n",
    "        elif mode == 'block':\n",
    "            item_block_cnt = self.df_train.groupby(['date_block_num', 'shop_id', 'item_id'])['item_cnt_day'].sum()\n",
    "            items_to_drop = item_block_cnt[item_block_cnt <= 0].index\n",
    "            self.df_train = self.df_train[~self.df_train.set_index(\n",
    "                                            ['date_block_num', 'shop_id', 'item_id']).index.isin(items_to_drop)]\n",
    "        elif mode == 'total':\n",
    "            item_total_cnt = self.df_train.groupby(['shop_id', 'item_id'])['item_cnt_day'].sum()\n",
    "            items_to_drop = item_total_cnt[item_total_cnt <= 0].index\n",
    "            self.df_train = self.df_train[~self.df_train.set_index(\n",
    "                                            ['shop_id', 'item_id']).index.isin(items_to_drop)]\n",
    "            \n",
    "        elif mode == 't+b':\n",
    "            item_total_cnt = self.df_train.groupby(['shop_id', 'item_id'])['item_cnt_day'].sum()\n",
    "            items_to_drop = item_total_cnt[item_total_cnt <= 0].index\n",
    "            self.df_train = self.df_train[~self.df_train.set_index(\n",
    "                                            ['shop_id', 'item_id']).index.isin(items_to_drop)]\n",
    "            \n",
    "            item_block_cnt = self.df_train.groupby(['date_block_num', 'shop_id', 'item_id'])['item_cnt_day'].sum()\n",
    "            items_to_drop = item_block_cnt[item_block_cnt <= 0].index\n",
    "            self.df_train = self.df_train[~self.df_train.set_index(\n",
    "                                            ['date_block_num', 'shop_id', 'item_id']).index.isin(items_to_drop)]\n",
    "            \n",
    "            \n",
    "        return\n",
    "        \n",
    "    def set_calender(self, calendar):\n",
    "        \n",
    "        calendar['date_block_num'] = (calendar['year'] - 2013)*12 + (calendar['month'] - 1)\n",
    "        calendar['hdays'] = calendar['mdays'] - calendar['wdays']\n",
    "        calendar.set_index('date_block_num', inplace=True)\n",
    "        \n",
    "        return calendar\n",
    "    \n",
    "    def items_ext(self):\n",
    "        \n",
    "        dfi = self.df_items.copy()\n",
    "        \n",
    "        dfi['fsb'] = self.df_train.groupby('item_id')['date_block_num'].min()\n",
    "        \n",
    "        dfi['fsb'].fillna(34, inplace=True)\n",
    "        dfi['fsb'] = dfi['fsb'].astype('int8')\n",
    "        \n",
    "        self.item_ext_features += ['fsb']\n",
    "        \n",
    "        return dfi\n",
    "    \n",
    "    def build_bb(self):\n",
    "        \n",
    "        if self.info: print('Building index dataframe...')\n",
    "\n",
    "        df_work = []\n",
    "\n",
    "        for block_num in self.df_train['date_block_num'].unique():\n",
    "    \n",
    "            cur_shops = self.df_train.loc[self.df_train['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "            cur_items = self.df_train.loc[self.df_train['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    \n",
    "            df_work.append(np.array(list(product(*[[block_num], cur_shops, cur_items])), dtype='int32'))\n",
    "\n",
    "        df_work = pd.DataFrame(np.vstack(df_work), columns = self.idx_columns)\n",
    "            \n",
    "        return df_work\n",
    "    \n",
    "    def df_train_agg(self, cmin = 0, cmax = 20, drop = None):\n",
    "        \n",
    "        if self.info: print('Aggregation...')\n",
    "        \n",
    "        df_work = self.df_train.groupby(self.idx_columns).agg({'item_price'  : np.mean, \n",
    "                                                               'item_cnt_day': np.sum})\n",
    "        df_work.reset_index(inplace=True)\n",
    "        df_work = df_work.rename(columns={'item_cnt_day': 'item_cnt_month'})\n",
    "        \n",
    "        df_work = pd.merge(self.df_bb, df_work, on=self.idx_columns, how='left')\n",
    "        \n",
    "        df_work['item_cnt_month'] = df_work['item_cnt_month'].astype('float32').fillna(0.).clip(cmin, cmax)\n",
    "        df_work['item_price'] = df_work['item_price'].astype('float32').fillna(0.)\n",
    "        \n",
    "        df_tmp = self.df_train[self.df_train['item_cnt_day'] > 0].groupby(self.idx_columns).agg({'item_cnt_day': 'count'})\n",
    "        df_tmp.reset_index(inplace=True)\n",
    "        df_tmp = df_tmp.rename(columns={'item_cnt_day': 'item_rate_month'})\n",
    "        \n",
    "        df_work = pd.merge(df_work, df_tmp, on=self.idx_columns, how='left')\n",
    "        \n",
    "        df_work['item_rate_month'] = df_work['item_rate_month'].astype('float32').fillna(0.)\n",
    "        \n",
    "        del df_tmp\n",
    "        \n",
    "        if drop: df_work.drop(drop, axis=1, inplace=True)\n",
    "        \n",
    "        return df_work\n",
    "    \n",
    "    def add_test_df(self):\n",
    "        \n",
    "        self.df_train_ext = pd.concat([self.df_train_ext, self.df_test], ignore_index=True,\n",
    "                                      sort=False, keys=self.idx_columns)\n",
    "    \n",
    "    def add_item_means(self, df, feature = None):\n",
    "        \n",
    "        # Adding item means\n",
    "        \n",
    "        if feature == None :\n",
    "            group_items = ['date_block_num','item_id']\n",
    "            feature = 'item_cnt'\n",
    "        else:\n",
    "            group_items = ['date_block_num','item_id'] + [feature]\n",
    "            \n",
    "        feature_mean_name = feature + '_mean'\n",
    "            \n",
    "        if self.info: print('Adding item means for', feature, '...')\n",
    "        \n",
    "        df_tmp = df.groupby(group_items)['item_cnt_month'].mean()\n",
    "        df_tmp = df_tmp.reset_index().rename(columns = {'item_cnt_month': feature_mean_name})\n",
    "        \n",
    "        df = pd.merge(df, df_tmp, on=group_items, how='left')\n",
    "        \n",
    "        self.item_mean_features.append(feature_mean_name)\n",
    "        \n",
    "        del df_tmp\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def add_shop_means(self, df, feature):\n",
    "        \n",
    "        # Adding shop means\n",
    "        \n",
    "        group_items = ['date_block_num', 'shop_id'] + [feature]\n",
    "            \n",
    "        feature_mean_name = feature + '_mean'\n",
    "            \n",
    "        if self.info: print('Adding shop means for', feature, '...')\n",
    "        \n",
    "        df_tmp = df.groupby(group_items)['item_cnt_month'].mean()\n",
    "        df_tmp = df_tmp.reset_index().rename(columns = {'item_cnt_month': feature_mean_name})\n",
    "        \n",
    "        df = pd.merge(df, df_tmp, on=group_items, how='left')\n",
    "        \n",
    "        self.shop_mean_features.append(feature)\n",
    "        \n",
    "        del df_tmp\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    \n",
    "    def df_train_extention(self, test_cat_only = False):\n",
    "        \n",
    "        df_work = self.df_train_ext.merge(df_shops[['city_enc', 'city_size']], how = 'left', on = 'shop_id')\n",
    "        \n",
    "        df_work = df_work.merge(self.calendar[['mdays', 'wdays', 'hdays']], \n",
    "                                how = 'left', left_on = 'date_block_num', right_index = True)\n",
    "        \n",
    "        df_work = df_work.merge(self.df_items_ext[self.item_ext_features],\n",
    "                                how = 'left', left_on = 'item_id', right_index = True)\n",
    "        \n",
    "        # Shop start block number\n",
    "        \n",
    "        ssbn = self.df_train.groupby('shop_id')['date_block_num'].min().astype('int8')\n",
    "        ssbn.name = 'ssbn'\n",
    "        df_work = df_work.merge(ssbn, how = 'left', on = 'shop_id')\n",
    "        \n",
    "        if test_cat_only:\n",
    "            test_cat = df_work[df_work['date_block_num'] == 34]['item_category_id'].unique()\n",
    "            df_work = df_work[df_work['item_category_id'].isin(test_cat)]\n",
    "\n",
    "        return df_work\n",
    "    \n",
    "    def make_base_df(self, keepnans = False):\n",
    "        \n",
    "        # Make base dataframe\n",
    "        \n",
    "        df_work = self.df_train_ext.copy()\n",
    "        \n",
    "        if keepnans:\n",
    "            fill_value = None\n",
    "        else:\n",
    "            fill_value = 0    \n",
    "            \n",
    "        df_work = pd.pivot_table(df_work, values='item_cnt_month', index=['shop_id', 'item_id'], \n",
    "                                     columns = 'date_block_num', aggfunc=np.sum, fill_value = fill_value)\n",
    "        df_work.columns.name = ''\n",
    "        \n",
    "        return df_work\n",
    "    \n",
    "    def add_total_cnt(self, df):\n",
    "        \n",
    "        if self.info: print('Adding total count...')\n",
    "        \n",
    "        df_base = self.make_base_df()\n",
    "        \n",
    "        for i in range(1, 33):\n",
    "            df_base[i + 1] += df_base[i]\n",
    "            \n",
    "        df_base = df_base.shift(1, axis=1).loc[:, 1:].astype('int32')\n",
    "        df_base = df_base.melt(var_name='date_block_num', value_name='total_cnt', ignore_index=False)\n",
    "        \n",
    "        df = df.merge(df_base, how='left', on=self.idx_columns)\n",
    "        \n",
    "        del df_base\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def add_item_lags(self, df, feature_name, nlags=3, keepnans=False, dnc=False):\n",
    "        \n",
    "        if self.info: print('Adding item lags for', feature_name, '...')\n",
    "    \n",
    "        df_tmp = df[['date_block_num', 'shop_id', 'item_id', feature_name]]\n",
    "    \n",
    "        for i in range(nlags, 0, -1):\n",
    "        \n",
    "            lag_feature_name = feature_name +'_lag-' + str(i)\n",
    "            if not dnc: self.lag_names_to_clip.append(lag_feature_name)\n",
    "        \n",
    "            df_shifted = df_tmp.copy()\n",
    "            df_shifted.columns = ['date_block_num', 'shop_id', 'item_id', lag_feature_name]\n",
    "            df_shifted['date_block_num'] += i\n",
    "            df = pd.merge(df, df_shifted, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n",
    "            \n",
    "            if keepnans:\n",
    "                df[lag_feature_name] = df[lag_feature_name].astype('float32')\n",
    "            else:\n",
    "                df[lag_feature_name] = df[lag_feature_name].fillna(0).astype('float32')\n",
    "        \n",
    "        del df_tmp\n",
    "    \n",
    "        return df\n",
    "    \n",
    "    def add_shop_lags(self, df, feature_name, nlags=3, dnc=False):\n",
    "        \n",
    "        mean_feature_name = feature_name + '_mean'\n",
    "        \n",
    "        if self.info: print('Adding lags for', mean_feature_name, '...')\n",
    "    \n",
    "        df_tmp = df[['date_block_num', 'shop_id', feature_name, mean_feature_name]]\n",
    "    \n",
    "        for i in range(nlags, 0, -1):\n",
    "        \n",
    "            lag_feature_name = mean_feature_name + '_lag-' + str(i)\n",
    "            if not dnc: self.lag_names_to_clip.append(lag_feature_name)\n",
    "        \n",
    "            df_shifted = df_tmp.copy()\n",
    "            df_shifted.columns = ['date_block_num', 'shop_id', feature_name, lag_feature_name]\n",
    "            df_shifted['date_block_num'] += i\n",
    "            df = pd.merge(df, df_shifted.drop_duplicates(), on=['date_block_num', 'shop_id', feature_name], how='left')\n",
    "            df[lag_feature_name] = df[lag_feature_name].fillna(0).astype('float32')\n",
    "        \n",
    "        del df_tmp\n",
    "        del df_shifted\n",
    "    \n",
    "        return df\n",
    "    \n",
    "    def shop_clustering(self, df_work):\n",
    "        \n",
    "        # Clustering algorithm can be defined at run time\n",
    "        \n",
    "        print('No shop clusters provided')\n",
    "        \n",
    "        return df_work\n",
    "    \n",
    "    def build_work_db(self, hd, item_mean_features = [], shop_mean_features = [], add_total_cnt = False):\n",
    "        \n",
    "        if self.info: print('Building work dataframe...')\n",
    "        \n",
    "        df_work = self.df_train_ext.copy()\n",
    "        \n",
    "        df_work = self.add_item_means(df_work)\n",
    "        \n",
    "        for mf in item_mean_features:\n",
    "            \n",
    "            df_work = self.add_item_means(df_work, mf)\n",
    "            \n",
    "        for mf in shop_mean_features:\n",
    "            \n",
    "            df_work = self.add_shop_means(df_work, mf)\n",
    "        \n",
    "        # Critical point: True or False (Affects qmean calculation)\n",
    "        df_work = self.add_item_lags(df_work, 'item_cnt_month', hd, keepnans=False)\n",
    "        df_work = self.add_item_lags(df_work, 'item_rate_month', hd, dnc=True)\n",
    "        df_work = self.add_item_lags(df_work, 'item_price', hd, dnc=True)\n",
    "            \n",
    "        for mf in self.item_mean_features:\n",
    "            \n",
    "            df_work = self.add_item_lags(df_work, mf, hd)\n",
    "            \n",
    "        for mf in self.shop_mean_features:\n",
    "            \n",
    "            df_work = self.add_shop_lags(df_work, mf, hd)\n",
    "        \n",
    "        df_work.drop(df_work[df_work['date_block_num'] < hd].index, inplace=True)\n",
    "        \n",
    "        df_work.drop(self.item_mean_features, axis=1, inplace=True)\n",
    "        df_work.drop(['item_category_id_mean', 'item_price', 'item_rate_month'], axis=1, inplace=True)\n",
    "        \n",
    "        self.item_mean_features = []\n",
    "        self.shop_mean_features = []\n",
    "        \n",
    "    \n",
    "        df_work['qmean'] = df_work[['item_cnt_month_lag-1', \n",
    "                                    'item_cnt_month_lag-2', \n",
    "                                    'item_cnt_month_lag-3']].mean(skipna=True, axis=1)\n",
    "        \n",
    "        df_work['new'] = df_work['fsb'] ==  df_work['date_block_num']\n",
    "        \n",
    "        df_work['fsb'] = df_work['date_block_num'] - df_work['fsb']\n",
    "        df_work['ssbn'] = df_work['date_block_num'] - df_work['ssbn']\n",
    "        \n",
    "        df_work['month'] = (df_work['date_block_num']%12).astype('int8')\n",
    "        \n",
    "        \n",
    "        idx = df_work[(df_work['item_price_lag-1'] == 0) & (df_work['item_price_lag-2'] != 0)].index\n",
    "        df_work.loc[idx, 'item_price_lag-1'] = df_work.loc[idx, 'item_price_lag-2']\n",
    "        idx = df_work[(df_work['item_price_lag-2'] == 0) & (df_work['item_price_lag-3'] != 0)].index\n",
    "        df_work.loc[idx, 'item_price_lag-2'] = df_work.loc[idx, 'item_price_lag-3']\n",
    "        \n",
    "        df_work['grad-1'] = df_work['item_cnt_month_lag-1']/df_work['item_cnt_month_lag-2']\n",
    "        df_work['grad-1'] = df_work['grad-1'].replace([np.inf, -np.inf], np.nan).fillna(0.)\n",
    "\n",
    "        df_work['grad-2'] = df_work['item_cnt_month_lag-2']/df_work['item_cnt_month_lag-3']\n",
    "        df_work['grad-2'] = df_work['grad-2'].replace([np.inf, -np.inf], np.nan).fillna(0.)\n",
    "        \n",
    "        # Shop clustering\n",
    "        \n",
    "        df_work = self.shop_clustering(df_work)\n",
    "        \n",
    "        # Moving total\n",
    "        \n",
    "        if add_total_cnt: df_work = self.add_total_cnt(df_work)\n",
    "            \n",
    "        # Clipping    \n",
    "  \n",
    "        col2clip = ['item_cnt_month', 'qmean'] + self.lag_names_to_clip\n",
    "        df_work[col2clip] = df_work[col2clip].clip(0, 20)\n",
    "        \n",
    "        return df_work\n",
    "    \n",
    "    def get_work_db(self, hd = 3, item_mean_features = [], \n",
    "                                  shop_mean_features = [], \n",
    "                                  drop_features = None,\n",
    "                                  add_total_cnt = False):\n",
    "        \n",
    "        df_work = self.build_work_db(hd, item_mean_features, shop_mean_features, add_total_cnt)\n",
    "\n",
    "        if drop_features == None:\n",
    "            return df_work\n",
    "        else:\n",
    "            return df_work.drop(drop_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning train dataframe... ( Mode - total )\n",
      "Building index dataframe...\n",
      "Aggregation...\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pfs = TT_Extended(df_train, df_test, items, df_shops, calendar, cmode='total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10987637 entries, 0 to 10987636\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   date_block_num    int32  \n",
      " 1   shop_id           int32  \n",
      " 2   item_id           int32  \n",
      " 3   item_price        float32\n",
      " 4   item_cnt_month    float32\n",
      " 5   item_rate_month   float32\n",
      " 6   city_enc          int8   \n",
      " 7   city_size         float32\n",
      " 8   mdays             int16  \n",
      " 9   wdays             int16  \n",
      " 10  hdays             int16  \n",
      " 11  item_category_id  int32  \n",
      " 12  hl_cat_id         int32  \n",
      " 13  fsb               int8   \n",
      " 14  ssbn              int8   \n",
      "dtypes: float32(4), int16(3), int32(5), int8(3)\n",
      "memory usage: 555.4 MB\n"
     ]
    }
   ],
   "source": [
    "pfs.df_train_ext.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define shop clustering methods\n",
    "\n",
    "def simple_shop_clustering(df_work):\n",
    "    \n",
    "    noisy_shops = [25, 31, 42]\n",
    "    df_work['shop_group'] = df_work['shop_id'].isin(noisy_shops)\n",
    "    \n",
    "    return df_work\n",
    "\n",
    "def knn_shop_clustering(df_work):\n",
    "    \n",
    "    df_sg = pd.pivot_table(df_work[df_work['item_cnt_month'] != 0], \n",
    "                           values='item_cnt_month', index=['shop_id'], \n",
    "                           columns = 'date_block_num', aggfunc='count', fill_value = 0)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=6, random_state=0).fit(df_sg)\n",
    "    df_sg['shop_group'] = kmeans.labels_.astype('int8')\n",
    "    df_work['shop_group'] = df_work['shop_id'].map(df_sg['shop_group'])\n",
    "    \n",
    "    del df_sg\n",
    "    \n",
    "    assert list(df_work[df_work['shop_group'].isna()]['shop_id'].unique()) == [], 'Missing shop found'\n",
    "    \n",
    "    return df_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfs.shop_clustering = simple_shop_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building work dataframe...\n",
      "Adding item means for item_cnt ...\n",
      "Adding item means for city_enc ...\n",
      "Adding shop means for item_category_id ...\n",
      "Adding item lags for item_cnt_month ...\n",
      "Adding item lags for item_rate_month ...\n",
      "Adding item lags for item_price ...\n",
      "Adding item lags for item_cnt_mean ...\n",
      "Adding item lags for city_enc_mean ...\n",
      "Adding lags for item_category_id_mean ...\n",
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_work = pfs.get_work_db(hd = 3, \n",
    "                          item_mean_features = ['city_enc'], \n",
    "                          shop_mean_features = ['item_category_id'], \n",
    "                          drop_features = ['wdays', 'hdays', 'ssbn'],\n",
    "                          add_total_cnt = False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9866074 entries, 1121563 to 10987636\n",
      "Data columns (total 34 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   date_block_num               int32  \n",
      " 1   shop_id                      int32  \n",
      " 2   item_id                      int32  \n",
      " 3   item_cnt_month               float32\n",
      " 4   city_enc                     int8   \n",
      " 5   city_size                    float32\n",
      " 6   mdays                        int16  \n",
      " 7   item_category_id             int32  \n",
      " 8   hl_cat_id                    int32  \n",
      " 9   fsb                          int32  \n",
      " 10  item_cnt_month_lag-3         float32\n",
      " 11  item_cnt_month_lag-2         float32\n",
      " 12  item_cnt_month_lag-1         float32\n",
      " 13  item_rate_month_lag-3        float32\n",
      " 14  item_rate_month_lag-2        float32\n",
      " 15  item_rate_month_lag-1        float32\n",
      " 16  item_price_lag-3             float32\n",
      " 17  item_price_lag-2             float32\n",
      " 18  item_price_lag-1             float32\n",
      " 19  item_cnt_mean_lag-3          float32\n",
      " 20  item_cnt_mean_lag-2          float32\n",
      " 21  item_cnt_mean_lag-1          float32\n",
      " 22  city_enc_mean_lag-3          float32\n",
      " 23  city_enc_mean_lag-2          float32\n",
      " 24  city_enc_mean_lag-1          float32\n",
      " 25  item_category_id_mean_lag-3  float32\n",
      " 26  item_category_id_mean_lag-2  float32\n",
      " 27  item_category_id_mean_lag-1  float32\n",
      " 28  qmean                        float32\n",
      " 29  new                          bool   \n",
      " 30  month                        int8   \n",
      " 31  grad-1                       float64\n",
      " 32  grad-2                       float64\n",
      " 33  shop_group                   bool   \n",
      "dtypes: bool(2), float32(21), float64(2), int16(1), int32(6), int8(2)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "df_work.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New features to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work['city_size'] = df_work['city_size'].round(1) # less noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_work[df_work.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n",
    "y_train = df_work[df_work.date_block_num < 33]['item_cnt_month']\n",
    "X_valid = df_work[df_work.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n",
    "y_valid = df_work[df_work.date_block_num == 33]['item_cnt_month']\n",
    "X_test = df_work[df_work.date_block_num == 34].drop(['item_cnt_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9430114 entries, 1121563 to 10551676\n",
      "Data columns (total 33 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   date_block_num               int32  \n",
      " 1   shop_id                      int32  \n",
      " 2   item_id                      int32  \n",
      " 3   city_enc                     int8   \n",
      " 4   city_size                    float32\n",
      " 5   mdays                        int16  \n",
      " 6   item_category_id             int32  \n",
      " 7   hl_cat_id                    int32  \n",
      " 8   fsb                          int32  \n",
      " 9   item_cnt_month_lag-3         float32\n",
      " 10  item_cnt_month_lag-2         float32\n",
      " 11  item_cnt_month_lag-1         float32\n",
      " 12  item_rate_month_lag-3        float32\n",
      " 13  item_rate_month_lag-2        float32\n",
      " 14  item_rate_month_lag-1        float32\n",
      " 15  item_price_lag-3             float32\n",
      " 16  item_price_lag-2             float32\n",
      " 17  item_price_lag-1             float32\n",
      " 18  item_cnt_mean_lag-3          float32\n",
      " 19  item_cnt_mean_lag-2          float32\n",
      " 20  item_cnt_mean_lag-1          float32\n",
      " 21  city_enc_mean_lag-3          float32\n",
      " 22  city_enc_mean_lag-2          float32\n",
      " 23  city_enc_mean_lag-1          float32\n",
      " 24  item_category_id_mean_lag-3  float32\n",
      " 25  item_category_id_mean_lag-2  float32\n",
      " 26  item_category_id_mean_lag-1  float32\n",
      " 27  qmean                        float32\n",
      " 28  new                          bool   \n",
      " 29  month                        int8   \n",
      " 30  grad-1                       float64\n",
      " 31  grad-2                       float64\n",
      " 32  shop_group                   bool   \n",
      "dtypes: bool(2), float32(20), float64(2), int16(1), int32(6), int8(2)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell was added to deal with Kaggle VM memory limitation\n",
    "del df_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 3974\n",
      "[LightGBM] [Info] Number of data points in the train set: 9430114, number of used features: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 0.296639\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.00427\tvalid_1's rmse: 0.910748\n",
      "[200]\ttraining's rmse: 0.902168\tvalid_1's rmse: 0.838488\n",
      "[300]\ttraining's rmse: 0.849975\tvalid_1's rmse: 0.809085\n",
      "[400]\ttraining's rmse: 0.821418\tvalid_1's rmse: 0.7974\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3020\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot update due to null objective function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3021\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[0;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "params = {\n",
    "    'objective': 'mse',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 255,\n",
    "    'learning_rate': 0.005,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 5,\n",
    "    'seed': 1,\n",
    "    'verbose': 1,\n",
    "    'force_row_wise' : True\n",
    "}\n",
    "\n",
    "categorical_feature_names = [ \n",
    "                            'item_category_id',\n",
    "                            'hl_cat_id', \n",
    "                            'city_enc',\n",
    "                            'month',\n",
    "                            'shop_group',\n",
    "                            'shop_id'\n",
    "                            ]\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train[feature_names], y_train, categorical_feature=None)\n",
    "lgb_eval  = lgb.Dataset(X_valid[feature_names], y_valid, categorical_feature=None, reference=lgb_train)\n",
    "\n",
    "evals_result = {}\n",
    "gbm = lgb.train(\n",
    "        params, \n",
    "        lgb_train,\n",
    "        num_boost_round = 4000,\n",
    "        valid_sets = (lgb_train, lgb_eval), \n",
    "        feature_name = feature_names,\n",
    "        categorical_feature = categorical_feature_names,\n",
    "        verbose_eval = 100, \n",
    "        evals_result = evals_result,\n",
    "        early_stopping_rounds = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20572/719582730.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m lgb.plot_importance(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mgbm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmax_num_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gain'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     figsize=(12,8));\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gbm' is not defined"
     ]
    }
   ],
   "source": [
    "lgb.plot_importance(\n",
    "    gbm, \n",
    "    max_num_features=50, \n",
    "    importance_type='gain', \n",
    "    figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['item_cnt_month'] = gbm.predict(X_test[feature_names]).clip(0, 20)\n",
    "sample_submission.to_csv('submission_k4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
